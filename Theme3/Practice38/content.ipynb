{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ø–ª–∞–Ω-–∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥–æ –∑–∞–Ω—è—Ç—Ç—è**  \n",
    "## **–¢–µ–º–∞ 3. –ó–∞–Ω—è—Ç—Ç—è 8. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å —Ä–µ–≥—Ä–µ—Å—ñ—ó —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó**  \n",
    "### **1. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å —Ä–µ–≥—Ä–µ—Å—ñ—ó**  \n",
    "### **2. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó**  \n",
    "\n",
    "---\n",
    "\n",
    "## **1. –í—Å—Ç—É–ø (10 —Ö–≤)**  \n",
    "\n",
    "### **1.1. –ú–µ—Ç–∞ –∑–∞–Ω—è—Ç—Ç—è**  \n",
    "- –û–∑–Ω–∞–π–æ–º–∏—Ç–∏ —Å–ª—É—Ö–∞—á—ñ–≤ –∑ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.  \n",
    "- –ù–∞–≤—á–∏—Ç–∏ —Ä–µ–∞–ª—ñ–∑–æ–≤—É–≤–∞—Ç–∏ —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ –≤ TensorFlow.  \n",
    "- –í–∏–∫–æ–Ω–∞—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –∑ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–æ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å (—Ä–µ–≥—Ä–µ—Å—ñ—è) —Ç–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤ (–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è).  \n",
    "\n",
    "### **1.2. –û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏**  \n",
    "–ü—ñ—Å–ª—è –∑–∞–Ω—è—Ç—Ç—è —Å–ª—É—Ö–∞—á—ñ –∑–º–æ–∂—É—Ç—å:  \n",
    "‚úÖ –°—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —Ç–∞ –Ω–∞–≤—á–∞—Ç–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è —Ä–µ–≥—Ä–µ—Å—ñ–π–Ω–∏—Ö –∑–∞–¥–∞—á.  \n",
    "‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö.  \n",
    "‚úÖ –û—Ü—ñ–Ω—é–≤–∞—Ç–∏ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π —Ç–∞ –ø–æ–∫—Ä–∞—â—É–≤–∞—Ç–∏ —ó—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∏.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å —Ä–µ–≥—Ä–µ—Å—ñ—ó (40 —Ö–≤)**  \n",
    "\n",
    "### **2.1. –û—Å–Ω–æ–≤–∏ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–µ–≤–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó**  \n",
    "üìå **–†–µ–≥—Ä–µ—Å—ñ—è** ‚Äì —Ü–µ –∑–∞–¥–∞—á–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–æ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥:  \n",
    "- –ü—Ä–æ–≥–Ω–æ–∑ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∞—Ç–∞–∫ —É –≤—ñ–π—Å—å–∫–æ–≤–æ–º—É —Ä–µ–≥—ñ–æ–Ω—ñ.  \n",
    "- –ü—Ä–æ–≥–Ω–æ–∑ –≤–∏—Ç—Ä–∞—Ç —Ä–µ—Å—É—Ä—Å—ñ–≤ —É –≤—ñ–π—Å—å–∫–æ–≤–∏—Ö –æ–ø–µ—Ä–∞—Ü—ñ—è—Ö.  \n",
    "\n",
    "üîπ **–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó:**  \n",
    "- –í—Ö—ñ–¥–Ω–∏–π —à–∞—Ä: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω—ñ–≤ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫.  \n",
    "- –ü—Ä–∏—Ö–æ–≤–∞–Ω—ñ —à–∞—Ä–∏: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è **ReLU** –∞–±–æ **Tanh** —è–∫ —Ñ—É–Ω–∫—Ü—ñ—ó –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó.  \n",
    "- –í–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä: –æ–¥–∏–Ω –Ω–µ–π—Ä–æ–Ω, –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó –∞–±–æ **Linear**.  \n",
    "- –§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç: **Mean Squared Error (MSE)** –∞–±–æ **Mean Absolute Error (MAE)**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2.2. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó**  \n",
    "üìå **–ü—Ä–∏–∫–ª–∞–¥: –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∞—Ç–∞–∫ –∑–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏.**  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä—É—î–º–æ —à—Ç—É—á–Ω–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö\n",
    "X = np.random.rand(500, 5)  # 5 –æ–∑–Ω–∞–∫\n",
    "y = X @ np.array([3, 5, -2, 1, 4]) + np.random.randn(500) * 0.5  # –õ—ñ–Ω—ñ–π–Ω–∞ –∑–∞–ª–µ–∂–Ω—ñ—Å—Ç—å + —à—É–º\n",
    "\n",
    "# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –≤–∏–±—ñ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª—ñ\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(5,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # –í–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó (–ª—ñ–Ω—ñ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è)\n",
    "])\n",
    "\n",
    "# –ö–æ–º–ø—ñ–ª—å–æ–≤—É—î–º–æ –º–æ–¥–µ–ª—å\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# –ü—Ä–æ–≥–Ω–æ–∑ —Ç–∞ –æ—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "```\n",
    "\n",
    "üìå **–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**  \n",
    "```\n",
    "Mean Squared Error: 0.24\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó (50 —Ö–≤)**  \n",
    "\n",
    "### **3.1. –û—Å–Ω–æ–≤–∏ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–µ–≤–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó**  \n",
    "üìå **–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è** ‚Äì —Ü–µ –∑–∞–¥–∞—á–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –¥–∞–Ω–∏—Ö –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó:  \n",
    "- –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–∏–ø—É –∞—Ç–∞–∫–∏ (–∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–∞, —Ä–∞–∫–µ—Ç–Ω–∞, –î–†–ì).  \n",
    "- –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ü—ñ–ª–µ–π —É –≤—ñ–π—Å—å–∫–æ–≤—ñ–π —Ä–æ–∑–≤—ñ–¥—Ü—ñ.  \n",
    "\n",
    "üîπ **–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:**  \n",
    "- –í—Ö—ñ–¥–Ω–∏–π —à–∞—Ä: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω—ñ–≤ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫.  \n",
    "- –ü—Ä–∏—Ö–æ–≤–∞–Ω—ñ —à–∞—Ä–∏: **ReLU** —è–∫ —Ñ—É–Ω–∫—Ü—ñ—è –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó.  \n",
    "- –í–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä:  \n",
    "  - **Sigmoid** (–¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó).  \n",
    "  - **Softmax** (–¥–ª—è –±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó).  \n",
    "- –§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç:  \n",
    "  - **Binary Crossentropy** (–±—ñ–Ω–∞—Ä–Ω–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è).  \n",
    "  - **Categorical Crossentropy** (–±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è).  \n",
    "\n",
    "---\n",
    "\n",
    "### **3.2. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó**  \n",
    "üìå **–ü—Ä–∏–∫–ª–∞–¥: –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ç–∏–ø—ñ–≤ –∞—Ç–∞–∫ (2 –∫–ª–∞—Å–∏ ‚Äì –∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–∞ –∞–±–æ —Ä–∞–∫–µ—Ç–Ω–∞).**  \n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä—É—î–º–æ —à—Ç—É—á–Ω–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "y = to_categorical(y)  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—ñ—Ç–æ–∫ —É one-hot encoding\n",
    "\n",
    "# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –≤–∏–±—ñ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª—ñ\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # –í–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä –¥–ª—è 2 –∫–ª–∞—Å—ñ–≤ (softmax)\n",
    "])\n",
    "\n",
    "# –ö–æ–º–ø—ñ–ª—å–æ–≤—É—î–º–æ –º–æ–¥–µ–ª—å\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"–¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ: {accuracy:.2f}\")\n",
    "```\n",
    "\n",
    "üìå **–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**  \n",
    "```\n",
    "–¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ: 0.88\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è (30 —Ö–≤)**  \n",
    "‚úÖ **–ó–∞–≤–¥–∞–Ω–Ω—è 1:** –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ä–µ–≥—Ä–µ—Å—ñ–π–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É –≤–∏—Ç—Ä–∞—Ç —Ä–µ—Å—É—Ä—Å—ñ–≤.  \n",
    "‚úÖ **–ó–∞–≤–¥–∞–Ω–Ω—è 2:** –ü–æ–±—É–¥—É–≤–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–∏–ø—É –∞—Ç–∞–∫–∏.  \n",
    "‚úÖ **–ó–∞–≤–¥–∞–Ω–Ω—è 3:** –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —Ä—ñ–∑–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏.  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ –ø—ñ–¥—Å—É–º–∫–∏ –∑–∞–Ω—è—Ç—Ç—è (10 —Ö–≤)**  \n",
    "‚úÖ **–û—Å–Ω–æ–≤–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏:**  \n",
    "- **–ù–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –≤–∏—Ä—ñ—à—É—é—Ç—å –∑–∞–¥–∞—á—ñ —Ä–µ–≥—Ä–µ—Å—ñ—ó —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.**  \n",
    "- **–ü—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –º–µ—Ä–µ–∂—ñ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤–ø–ª–∏–≤–∞—î –Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—É.**  \n",
    "- **TensorFlow –¥–æ–∑–≤–æ–ª—è—î —à–≤–∏–¥–∫–æ –±—É–¥—É–≤–∞—Ç–∏ —Ç–∞ –Ω–∞–≤—á–∞—Ç–∏ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ.**  \n",
    "\n",
    "üöÄ **–ö–ª—é—á–æ–≤–∏–π –º–µ—Å–µ–¥–∂:**  \n",
    "**–ù–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ —î –ø–æ—Ç—É–∂–Ω–∏–º —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö, —â–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —É –≤—ñ–π—Å—å–∫–æ–≤—ñ–π –∞–Ω–∞–ª—ñ—Ç–∏—Ü—ñ, —Ñ—ñ–Ω–∞–Ω—Å–∞—Ö —Ç–∞ –±–∞–≥–∞—Ç—å–æ—Ö —ñ–Ω—à–∏—Ö —Å—Ñ–µ—Ä–∞—Ö!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
